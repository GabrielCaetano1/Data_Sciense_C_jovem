{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrESA9Ehul9A"
      },
      "source": [
        "\n",
        "### **Atividade Prática: Introdução ao Processamento de Linguagem Natural (NLP)**  \n",
        "\n",
        "#### **Objetivos da Atividade**  \n",
        "1. Compreender os conceitos fundamentais do Processamento de Linguagem Natural (NLP) em português.  \n",
        "2. Aplicar técnicas de pré-processamento de texto, incluindo remoção de stopwords, stemming e lematização.  \n",
        "3. Explorar e comparar diferentes representações de texto (Bag of Words e TF-IDF).  \n",
        "4. Desenvolver modelos de classificação de sentimentos e comparar métricas de desempenho.  \n",
        "\n",
        "#### **Sumário**  \n",
        "1. Introdução ao NLP.  \n",
        "2. Importação das bibliotecas necessárias.  \n",
        "3. Baixar os datasets de NLP.  \n",
        "4. Análise do dataset e descrição.  \n",
        "5. Expressões regulares para limpeza de texto.  \n",
        "6. Remoção de stopwords.  \n",
        "7. Lemmatização e Stemming (com tabela comparativa).  \n",
        "8. Representação de texto com Bag of Words.  \n",
        "9. Representação de texto com TF-IDF.  \n",
        "10. Classificação de sentimentos.  \n",
        "  \n",
        "\n",
        "---\n",
        "\n",
        "### **1) Introdução ao NLP**  \n",
        "O Processamento de Linguagem Natural (NLP) é uma subárea da Inteligência Artificial que busca criar sistemas capazes de entender, interpretar e gerar texto ou fala em linguagem humana.  \n",
        "\n",
        "Aplicações comuns de NLP incluem:  \n",
        "- Análise de sentimentos.  \n",
        "- Tradução automática.  \n",
        "- Resumo de texto.  \n",
        "- Sistemas de busca.  \n",
        "- Assistentes virtuais.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAl28BFAu0I9"
      },
      "source": [
        "\n",
        "### **2) Importação das bibliotecas necessárias**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2PpL1dhFzi_",
        "outputId": "a900254b-9ed7-44b1-a89e-34ec28828440"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxFBf6EnjxyT",
        "outputId": "64a9c9d6-a91d-4476-e10f-ef2aa8a2d145"
      },
      "outputs": [],
      "source": [
        "# Importação das bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import random\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')  # Stemmer em português\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1hs_vCvRsX"
      },
      "source": [
        "### **3) Dataset sintético para classificação de sentimentos**  \n",
        "Utilizaremos um dataset sintético em português com dados de sentimentos. Este consiste em reviews de produtos, onde cada texto é rotulado com um sentimento: positivo ou negativo. Esta tarefa é uma **classificação supervisionada**, pois usamos os rótulos (variável dependente) para treinar e avaliar o modelo.\n",
        "\n",
        "**Descrição das variáveis**:  \n",
        "- `review`: texto contendo a opinião do usuário.  \n",
        "- `sentiment`: rótulo associado à opinião (positivo = 1, negativo = 0).  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "GikMfubMvZhd"
      },
      "outputs": [],
      "source": [
        "# Expansão das listas de frases positivas e negativas\n",
        "frases_positivas_treino = [\n",
        "    \"Adorei o produto! #satisfeito\", \"Excelente qualidade, recomendo! @lojaTop\",\n",
        "    \"Superou minhas expectativas! Veja em https://produto.com/top\",\n",
        "    \"Muito bom, chegou antes do prazo. #ótimaCompra\",\n",
        "    \"Gostei bastante, produto perfeito. Obrigado @vendedor!\",\n",
        "    \"Ótima experiência de compra. #Recomendo\",\n",
        "    \"Funciona perfeitamente, estou muito satisfeito. Veja mais: https://review.com/produto\",\n",
        "    \"Produto incrível, muito útil! @superLoja\",\n",
        "    \"Chegou em perfeito estado e adorei. #Top\",\n",
        "    \"Com certeza compraria novamente! Veja aqui: https://loja.com/perfeito\",\n",
        "    \"Entrega rápida e eficiente. #rapidez\",\n",
        "    \"Valeu muito a pena, recomendo! Confira @lojaBoa\",\n",
        "    \"Produto cumpre o prometido. Veja em https://produto.com\",\n",
        "    \"A embalagem estava impecável, nota 10. #embalagemTop\",\n",
        "    \"Compra maravilhosa, super satisfeita! #Maravilhoso\",\n",
        "    \"Atendimento incrível, me ajudaram muito. @AtendimentoPro\",\n",
        "    \"Sem dúvidas, a melhor compra do ano! Veja: https://compras.com/melhor\",\n",
        "    \"Estou impressionado com a qualidade. #QualidadeImpressionante\",\n",
        "    \"Chegou antes do prazo e é tudo que eu precisava. #EntregaPerfeita\",\n",
        "    \"Melhor custo-benefício, recomendo a todos! #custoBeneficio\",\n",
        "    \"Incrível como o produto é eficiente. Confira: https://produto.com/eficiencia\",\n",
        "    \"A equipe está de parabéns pelo serviço. @EquipeTop\",\n",
        "    \"Produto fantástico, mudou minha rotina. Veja mais: https://produto.com/fantastico\",\n",
        "    \"Superou todas as expectativas, parabéns @LojaBoa! #Top\",\n",
        "    \"Recomendo para amigos e familiares, é excelente! #Recomendo\"\n",
        "]\n",
        "\n",
        "frases_positivas_teste = [\n",
        "    \"A loja é excelente, tudo perfeito! #topLoja\",\n",
        "    \"Adorei a embalagem, muito cuidadosa. @embalagemPro\",\n",
        "    \"Recomendo sem dúvidas, ótimo serviço. Veja: https://servico.com/otimo\",\n",
        "    \"Tudo veio conforme descrito, muito bom. #Confiável\",\n",
        "    \"Ficou perfeito para o que eu precisava. #Perfeito\",\n",
        "    \"O presente foi um sucesso! Obrigado @lojaPresente\",\n",
        "    \"Muito melhor do que eu esperava. Confira mais: https://produto.com/incrivel\",\n",
        "    \"Parabéns pelo ótimo atendimento! #obrigado\",\n",
        "    \"Estou muito feliz com a compra! #feliz\",\n",
        "    \"Material de ótima qualidade. #qualidade\",\n",
        "    \"Fiquei impressionado com a qualidade. @marcaTop\",\n",
        "    \"Compra totalmente satisfatória. Confira: https://compra.com/satisfeito\",\n",
        "    \"Chegou rápido e o atendimento foi excelente. #RapidezEficiente\",\n",
        "    \"Melhor loja que já comprei, tudo perfeito. @LojaTop\",\n",
        "    \"O produto é tão bom que comprei mais um! #ProdutoTop\",\n",
        "    \"Recomendo para qualquer pessoa que procure qualidade. @QualidadeBoa\",\n",
        "    \"Vale cada centavo, produto de primeira. #Recomendo\",\n",
        "    \"Ótima solução para minhas necessidades. Veja: https://produto.com/solucao\",\n",
        "    \"Me surpreendeu em todos os aspectos. @LojaIncrivel\",\n",
        "    \"Não esperava tanto, mas foi maravilhoso. #MaravilhosoExtra\"\n",
        "]\n",
        "\n",
        "frases_negativas_treino = [\n",
        "    \"Produto horrível, não recomendo. #decepção\", \"Péssima experiência, muito ruim. @lojaRuim\",\n",
        "    \"Chegou quebrado, total decepção. Veja: https://produto.com/quebrado\",\n",
        "    \"Material de qualidade muito baixa. #ruim\",\n",
        "    \"Não funciona como descrito, muito insatisfeito. Veja: https://review.com/insatisfeito\",\n",
        "    \"Entrega atrasada, serviço ruim. #atraso\",\n",
        "    \"Produto caro e de má qualidade. Veja @lojaCara\",\n",
        "    \"Não gostei, nunca mais compro aqui. #péssimo\",\n",
        "    \"Descrição enganosa, perdi dinheiro. Veja mais: https://enganoso.com\",\n",
        "    \"Horrível, arrependido da compra. @lojaPéssima\",\n",
        "    \"Experiência frustrante, não recomendo. #frustração\",\n",
        "    \"Produto veio errado, muito descaso. Veja @suporteRuim\",\n",
        "    \"Produto não entregou o que prometia, fiquei insatisfeito. #promessaFalsa\",\n",
        "    \"Paguei caro e recebi algo muito inferior. Veja mais: @DescontoRuim\",\n",
        "    \"Reclamei com o suporte e não me ajudaram. #SuportePéssimo\",\n",
        "    \"É uma fraude, tomem cuidado. Veja: https://fraude.com\",\n",
        "    \"Muito abaixo das expectativas. @ExpectativaRuim\",\n",
        "    \"Entrega demorou semanas, total descaso. #AtrasoEntrega\",\n",
        "    \"O produto veio com defeito e não funciona. #DefeitoProduto\",\n",
        "    \"Não recomendo, foi uma experiência frustrante. Veja: https://frustrante.com\"\n",
        "]\n",
        "\n",
        "frases_negativa_teste = [\n",
        "    \"Foi uma completa perda de tempo. Veja mais: https://perda.com\",\n",
        "    \"O suporte da loja é péssimo. #suporteRuim\",\n",
        "    \"Infelizmente não funcionou nada. Veja: https://produto.com/nãoFunciona\",\n",
        "    \"Muito frágil, quebrou no primeiro uso. @produtoRuim\",\n",
        "    \"Chegou sujo e mal embalado. #péssimo\",\n",
        "    \"A descrição era completamente falsa. @falsidade\",\n",
        "    \"Muito caro pelo que oferece. Veja: https://custo.com/alto\",\n",
        "    \"Não atendeu as minhas expectativas. @lojaDecepcionante\",\n",
        "    \"Infelizmente foi uma péssima compra. Veja: https://péssimo.com\",\n",
        "    \"Não vale o preço pago. #caro\",\n",
        "    \"Não comprem, é uma armadilha. Veja: https://cuidado.com\",\n",
        "    \"Decepcionante, esperava mais. @compraRuim\",\n",
        "    \"A qualidade é extremamente ruim. #ruim\",\n",
        "    \"Produto com prazo de validade vencido. @ProblemaProduto\",\n",
        "    \"Recebi algo completamente diferente do anunciado. Veja mais: https://enganoso.com\",\n",
        "    \"O produto parou de funcionar após um dia de uso. #DurabilidadeRuim\",\n",
        "    \"Muito caro e a qualidade não corresponde. @CustoBeneficioRuim\",\n",
        "    \"Nunca mais compro dessa loja, foi decepcionante. #LojaRuim\",\n",
        "    \"As especificações são totalmente falsas. Veja: https://produto.com/mentira\",\n",
        "    \"Me arrependi completamente da compra. @Arrependimento\"\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpYMKU-eiMF1"
      },
      "source": [
        "### **Geraçaõ do conjunto de Treino**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kDvyqrFa08nV",
        "outputId": "e0361f2f-0c64-47eb-a8c0-1203f81e8837"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Função para gerar combinações de frases\n",
        "def gerar_review(frases, num_frases=4):\n",
        "    return \" \".join(random.sample(frases, num_frases))\n",
        "\n",
        "# Gerar exemplos sintéticos\n",
        "reviews_train = []\n",
        "sentiments_train = []\n",
        "\n",
        "# Gerar 250 exemplos positivos\n",
        "for _ in range(200):\n",
        "    reviews_train.append(gerar_review(frases_positivas_treino, random.randint(1, 4)))  # Combina 1 a 5 frases positivas\n",
        "    sentiments_train.append(1)\n",
        "\n",
        "# Gerar 250 exemplos negativos\n",
        "for _ in range(200):\n",
        "    reviews_train.append(gerar_review(frases_negativas_treino, random.randint(1, 4)))  # Combina 1 a 5 frases negativas\n",
        "    sentiments_train.append(0)\n",
        "\n",
        "# Misturar os exemplos\n",
        "data_treino = pd.DataFrame({'review': reviews_train, 'sentiment': sentiments_train}).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Exibir as primeiras linhas do dataset\n",
        "data_treino\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTzRTAtfiZMj"
      },
      "source": [
        "### **Geraçaõ do conjunto de Teste**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "W-8LznoiPp6W",
        "outputId": "094426a3-ae60-4307-c39f-5daf7535ddb5"
      },
      "outputs": [],
      "source": [
        "# Gerar exemplos sintéticos\n",
        "reviews_test = []\n",
        "sentiments_test = []\n",
        "\n",
        "# Gerar 250 exemplos positivos\n",
        "for _ in range(150):\n",
        "    reviews_test.append(gerar_review(frases_positivas_teste, random.randint(1, 4)))  # Combina 1 a 5 frases positivas\n",
        "    sentiments_test.append(1)\n",
        "\n",
        "# Gerar 250 exemplos negativos\n",
        "for _ in range(150):\n",
        "    reviews_test.append(gerar_review(frases_negativa_teste, random.randint(1, 4)))  # Combina 1 a 5 frases negativas\n",
        "    sentiments_test.append(0)\n",
        "\n",
        "# Misturar os exemplos\n",
        "data_test = pd.DataFrame({'review': reviews_test, 'sentiment': sentiments_test}).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Exibir as primeiras linhas do dataset\n",
        "data_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "Mp_ydGWa1Rmk",
        "outputId": "8d8ee4bc-69a5-4726-f8da-ff7b39137c50"
      },
      "outputs": [],
      "source": [
        "# Análise de distribuição\n",
        "print(\"\\nDistribuição de classes:\")\n",
        "data_treino['sentiment'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "dVEcLWzfRc1c",
        "outputId": "d9dd5e64-5f95-48b3-de8a-4fe5d7d9d5fa"
      },
      "outputs": [],
      "source": [
        "# Análise de distribuição\n",
        "print(\"\\nDistribuição de classes:\")\n",
        "data_test['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R86C89ZQxNZm"
      },
      "source": [
        "### **5) Expressões Regulares para Limpeza de Texto**  \n",
        "\n",
        "As expressões regulares (Regex) são ferramentas poderosas para identificar padrões em textos. Durante o pré-processamento, são usadas para:  \n",
        "1. Remover links, hashtags e menções.  \n",
        "2. Substituir caracteres especiais e números.  \n",
        "3. Uniformizar o texto (ex.: converter para minúsculas).\n",
        "\n",
        "**Fórmulas e exemplos**:  \n",
        "- Para remover URLs: `re.sub(r\"http\\S+\", \"\", texto)`  \n",
        "- Para remover números: `re.sub(r\"\\d+\", \"\", texto)`  \n",
        "\n",
        "\n",
        "\n",
        "| **Expressão Regular** | **Descrição** | **Exemplo** |\n",
        "|-----------------------|---------------|-------------|\n",
        "| `\\d`                  | Qualquer dígito (0-9) | `'123'.match(r'\\d')` (True) |\n",
        "| `\\D`                  | Qualquer caractere que não seja dígito | `'a'.match(r'\\D')` (True) |\n",
        "| `\\w`                  | Qualquer caractere alfanumérico (letras, números e _) | `'abc123'.match(r'\\w')` (True) |\n",
        "| `\\W`                  | Qualquer caractere que não seja alfanumérico | `'@'.match(r'\\W')` (True) |\n",
        "| `\\s`                  | Espaço em branco, incluindo espaços, tabs e novas linhas | `' '.match(r'\\s')` (True) |\n",
        "| `\\S`                  | Qualquer caractere que não seja espaço em branco | `'a'.match(r'\\S')` (True) |\n",
        "| `^`                   | Início da string | `re.match(r'^a', 'abc')` (True) |\n",
        "| `$`                   | Fim da string | `re.match(r'abc$', 'abc')` (True) |\n",
        "| `.`                   | Qualquer caractere, exceto nova linha | `'a'.match(r'.')` (True) |\n",
        "| `*`                   | Zero ou mais repetições do padrão anterior | `'aaaa'.match(r'a*')` (True) |\n",
        "| `+`                   | Uma ou mais repetições do padrão anterior | `'aaa'.match(r'a+')` (True) |\n",
        "| `?`                   | Zero ou uma repetição do padrão anterior | `'a'.match(r'a?')` (True) |\n",
        "| `{n}`                 | Exatamente n repetições do padrão anterior | `'aaa'.match(r'a{3}')` (True) |\n",
        "| `{n,}`                | Pelo menos n repetições do padrão anterior | `'aaaa'.match(r'a{3,}')` (True) |\n",
        "| `{n,m}`               | Entre n e m repetições do padrão anterior | `'aabb'.match(r'a{2,3}')` (True) |\n",
        "| `[]`                  | Conjunto de caracteres | `'a'.match(r'[abc]')` (True) |\n",
        "| `|`                   | Ou | `'a'.match(r'a|b')` (True) |\n",
        "| `()`                  | Agrupamento de padrões | `re.match(r'(abc)+', 'abcabc')` (True) |\n",
        "| `\\b`                  | Limite de palavra | `'abc'.match(r'\\babc\\b')` (True) |\n",
        "| `\\B`                  | Não-limite de palavra | `'abc'.match(r'\\Babc\\B')` (False) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "CHuUTX9VxE4t",
        "outputId": "334a793b-c01b-4561-ac44-c8b03bb91a2a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Função de limpeza\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)    # Remove menções\n",
        "    text = re.sub(r\"#\\w+\", \"\", text)    # Remove hashtags\n",
        "    text = re.sub(r\"[^a-zA-Záéíóúçãõ ]\", \" \", text)  # Remove caracteres especiais\n",
        "    text = text.lower()  # Converte para minúsculas\n",
        "    return text\n",
        "\n",
        "data_treino['cleaned_review'] = data_treino['review'].apply(clean_text)\n",
        "data_treino[['review', 'cleaned_review']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Z9sDguaeRxE3",
        "outputId": "694b7acb-e43b-4234-ad7f-740def750a3c"
      },
      "outputs": [],
      "source": [
        "data_test['cleaned_review'] = data_test['review'].apply(clean_text)\n",
        "data_test[['review', 'cleaned_review']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTbV4KI46bkS"
      },
      "source": [
        "\n",
        "### **6) Remoção de Stopwords**  \n",
        "\n",
        "Stopwords são palavras frequentes (como \"de\", \"a\", \"e\") que normalmente não carregam informações úteis para o modelo.  \n",
        "\n",
        "A remoção de stopwords reduz a dimensionalidade do texto e ajuda a focar em palavras mais relevantes.  \n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ht4BQswZ6fQS",
        "outputId": "bdbfc354-a10f-4479-c938-5da20060c7b3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Stopwords em português\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Remover \"não\" da lista de stopwords\n",
        "stop_words.discard(\"não\")\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    return \" \".join([word for word in words if word not in stop_words])\n",
        "\n",
        "data_treino['no_stopwords'] = data_treino['cleaned_review'].apply(remove_stopwords)\n",
        "data_treino[['cleaned_review', 'no_stopwords']]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NcIx1TKgSepl",
        "outputId": "712d1306-eba5-4042-a197-968ec4402cd4"
      },
      "outputs": [],
      "source": [
        "data_test['no_stopwords'] = data_test['cleaned_review'].apply(remove_stopwords)\n",
        "data_test[['cleaned_review', 'no_stopwords']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkxPdie78djb"
      },
      "source": [
        "### **7) Lemmatização e Stemming**  \n",
        "\n",
        "- **Stemming**: Reduz as palavras à sua raiz, sem considerar o significado. (Ex.: \"correr\", \"correu\" → \"corr\").  \n",
        "- **Lemmatização**: Reduz as palavras à forma base considerando seu contexto gramatical. (Ex.: \"correu\" → \"correr\").  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RcQD-Ye-87FB",
        "outputId": "4ebe3166-12b5-4095-bc05-c12050914e40"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('pt_core_news_sm')\n",
        "# Função de Stemming\n",
        "def stemming(text):\n",
        "    stemmer = RSLPStemmer()\n",
        "    words = word_tokenize(text, language='portuguese')\n",
        "    return \" \".join([stemmer.stem(word) for word in words])\n",
        "\n",
        "# Função de Lemmatization\n",
        "def lemmatization(text):\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "data_treino['Stemmed'] = data_treino['no_stopwords'].apply(stemming)\n",
        "data_treino['Lemmatized'] = data_treino['no_stopwords'].apply(lemmatization)\n",
        "\n",
        "data_treino[['no_stopwords','Lemmatized','Stemmed']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-g8jlJvGIbH2",
        "outputId": "56ce4c74-4963-4384-efc3-dce34242d890"
      },
      "outputs": [],
      "source": [
        "data_test['Stemmed'] = data_test['no_stopwords'].apply(stemming)\n",
        "data_test['Lemmatized'] = data_test['no_stopwords'].apply(lemmatization)\n",
        "\n",
        "data_test[['no_stopwords','Lemmatized','Stemmed']].head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hvUWTGdGQpV"
      },
      "source": [
        "### **8) Representação de Texto com Bag of Words**  \n",
        "**Fundamentação Teórica**:  \n",
        "O modelo **Bag of Words (BoW)** cria uma matriz de frequências de palavras.  \n",
        "\n",
        "Seja um conjunto $( D )$ com $( n )$ documentos e $( m )$ termos:  \n",
        "- Elemento $( A[i][j] )$ indica a frequência do termo $( j )$ no documento $( i)$.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFgySrJyG5XY",
        "outputId": "f3f65e6b-0432-4477-d973-3efba695d913"
      },
      "outputs": [],
      "source": [
        "\n",
        "cv = CountVectorizer()\n",
        "X_cv = cv.fit_transform(data_treino['no_stopwords'])\n",
        "\n",
        "print(\"Shape da matriz:\", X_cv.shape)\n",
        "print(\"Exemplo de matriz:\",)\n",
        "X_cv.toarray()[:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY-HxqyCHoni"
      },
      "source": [
        "### **9) Representação de Texto com TF-IDF**  \n",
        "\n",
        "A técnica **TF-IDF** atribui peso maior a termos relevantes e menos frequentes em um corpus.  \n",
        "\n",
        "Equação:  \n",
        "$\n",
        "TF\\text{-}IDF(t,d) = TF(t,d) \\times \\log\\left(\\frac{N}{DF(t)}\\right)\n",
        "$\n",
        "Onde:  \n",
        "- $( TF(t,d) )$: frequência do termo \\( t \\) no documento \\( d \\).  \n",
        "- $( DF(t) $): número de documentos contendo o termo \\( t \\).  \n",
        "- $( N $): total de documentos.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uey5HvANHt8y",
        "outputId": "aa99087e-77c3-4066-bb6a-1e6b522723d6"
      },
      "outputs": [],
      "source": [
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "X_tfidf = tfidf.fit_transform(data_treino['no_stopwords'])\n",
        "\n",
        "print(\"Shape da matriz:\", X_tfidf.shape)\n",
        "print(\"Exemplo de matriz:\")\n",
        "X_tfidf.toarray()[:5]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAsoOFDuu7Pt"
      },
      "source": [
        "\n",
        "### **10) Classificação de Sentimentos**  \n",
        "\n",
        "Uma tarefa importante em Processamento de Linguagem Natural (NLP) que visa identificar a atitude emocional expressa em um texto. Em geral, a classificação de sentimentos envolve a categorização de opiniões ou reviews em rótulos como **positivo**, **negativo** ou **neutro**. No contexto desta atividade, o objetivo é classificar reviews de produtos como **positivos** ou **negativos**.\n",
        "\n",
        "A regressão logística foi escolhida como modelo para essa tarefa devido à sua simplicidade, eficiência e capacidade de lidar bem com tarefas de classificação binária, como esta.\n",
        "\n",
        "##### **Desafios da Classificação de Sentimentos com Regressão Logística**\n",
        "Embora a regressão logística seja uma boa escolha para tarefas de classificação binária, ela pode não capturar completamente as dependências mais complexas no texto, como as interações entre palavras em frases mais longas ou o contexto em que as palavras são usadas. Isso pode ser uma limitação quando se lida com textos mais complicados ou quando a relação entre as características e o sentimento não é linear.\n",
        "\n",
        "##### **Avaliação do Modelo**\n",
        "Para avaliar a performance do modelo de regressão logística, é fundamental utilizar métricas adequadas. Como o problema é de classificação binária, as principais métricas incluem:\n",
        "- **Acurácia:** A proporção de classificações corretas em relação ao total de classificações.\n",
        "- **Precisão e Recall:** Importantes quando se busca minimizar erros de classificação em uma das classes, como por exemplo, evitar a classificação incorreta de reviews positivas como negativas.\n",
        "- **F1-Score:** A média harmônica entre precisão e recall, útil para avaliar o equilíbrio entre esses dois aspectos.\n",
        "- **Matriz confusão:** permite indenticar a exata quantidade de Falsos Positivos, Falsos negativos e Verdadeios positivos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "LZ2le2LPvLWM",
        "outputId": "649ee56d-79fa-4fb4-e3da-2d222ea4bb8c"
      },
      "outputs": [],
      "source": [
        "# Separar features (X) e rótulos (y)\n",
        "X_train = data_treino['review']\n",
        "y_train = data_treino['sentiment']\n",
        "\n",
        "X_test = data_test['review']\n",
        "y_test = data_test['sentiment']\n",
        "\n",
        "# Vetorização usando CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Modelo de classificação\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNWLgDNmbBs8"
      },
      "source": [
        "#### **10.1) Classificação de Sentimentos com pré-processamento Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "VuNaMlSVbMo8",
        "outputId": "a736624f-608d-4fc4-9694-af16a2454adc"
      },
      "outputs": [],
      "source": [
        "# Separar features (X) e rótulos (y)\n",
        "X_train = data_treino['Stemmed']\n",
        "y_train = data_treino['sentiment']\n",
        "\n",
        "X_test = data_test['Stemmed']\n",
        "y_test = data_test['sentiment']\n",
        "\n",
        "# Vetorização usando CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Modelo de classificação\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrAbe-LEcZ27"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ry3xN43cdPO"
      },
      "source": [
        "#### **10.2) Classificação de Sentimentos com pré-processamento e TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "0PPuTkSAbnEf",
        "outputId": "49540472-eac0-4ec5-bf66-106e71f148b6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Vetorização usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Modelo de classificação\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaURtUPpcuCs"
      },
      "source": [
        "#### **10.3) Classificação de Sentimentos com pré-processamento, TF-IDF e utilizando Naive Bayes como modelo para classificação**\n",
        "\n",
        "\n",
        "O **Naive Bayes** é um modelo probabilístico amplamente utilizado em tarefas de **classificação de texto**, incluindo a **classificação de sentimentos**. Seu principal fundamento é o **Teorema de Bayes**, que aplica a probabilidade condicional para prever a classe de uma instância com base nas suas características.\n",
        "\n",
        "Neste caso, o objetivo é classificar **reviews de produtos** como **positivas** ou **negativas** com base nas palavras ou termos que aparecem no texto. O Naive Bayes é uma excelente escolha devido à sua simplicidade, eficiência e boa performance em problemas de texto.\n",
        "\n",
        "###### **Princípio Básico do Naive Bayes**\n",
        "O modelo de Naive Bayes baseia-se no **Teorema de Bayes**, que descreve a probabilidade de uma classe \\( C \\) dada uma instância de dados \\( X \\), que é composta por características (neste caso, as palavras do texto):\n",
        "\n",
        "$\n",
        "P(C|X) = \\frac{P(X|C)P(C)}{P(X)}\n",
        "$\n",
        "\n",
        "Onde:\n",
        "- $( P(C|X) )$ é a probabilidade de \\( X \\) pertencer à classe \\( C \\) (por exemplo, positivo ou negativo) dado \\( X \\) (as palavras no texto).\n",
        "- $( P(X|C) )$ é a probabilidade de observar o conjunto de características \\( X \\) dado que a classe é \\( C \\).\n",
        "- $( P(C) )$ é a probabilidade a priori de cada classe (por exemplo, a probabilidade de um review ser positivo ou negativo antes de observar o texto).\n",
        "- $( P(X) )$ é a probabilidade de observar as características \\( X \\) em qualquer classe (também chamada de **evidência**).\n",
        "\n",
        "\n",
        "No caso da **classificação de sentimentos**, o objetivo é determinar se um review é **positivo** ou **negativo** com base nas palavras presentes nele. Cada review pode ser visto como uma sequência de características (as palavras ou termos), e o Naive Bayes tenta calcular qual é a classe mais provável (positiva ou negativa) dado o conjunto de palavras.\n",
        "\n",
        "O modelo aprende a **probabilidade a priori** de cada classe (quanto um review tende a ser positivo ou negativo) e a **probabilidade condicional** de cada palavra ocorrer em reviews positivos ou negativos. Com isso, ele é capaz de calcular a probabilidade de cada classe e escolher a classe com maior probabilidade.\n",
        "\n",
        "###### **Vantagens do Naive Bayes**\n",
        "- **Simplicidade:** O Naive Bayes é fácil de entender e implementar, o que o torna uma excelente escolha para tarefas iniciais de classificação de sentimentos.\n",
        "- **Eficiência:** Devido à sua suposição de independência entre palavras, o modelo pode ser treinado rapidamente, mesmo em grandes volumes de dados de texto.\n",
        "- **Bom Desempenho em Texto:** O Naive Bayes tem mostrado bons resultados em várias tarefas de NLP, como análise de sentimentos, detecção de spam, e outras, mesmo com a suposição de independência, que é muitas vezes não completamente verdadeira.\n",
        "- **Robustez:** Mesmo quando a suposição de independência entre palavras não é totalmente válida, o modelo ainda pode funcionar bem, especialmente quando as palavras são indicativas de uma classe específica.\n",
        "\n",
        "##### **Desvantagens**\n",
        "- **Independência entre Características:** A principal limitação do Naive Bayes é a suposição de que as características (palavras) são independentes. Em textos, as palavras frequentemente dependem umas das outras, o que pode afetar a performance do modelo em textos mais complexos ou com dependências entre palavras.\n",
        "- **Modelagem de Dependências Limitada:** Como o modelo não consegue capturar dependências entre palavras, ele pode falhar em capturar nuances de significado que dependem do contexto da palavra, como no caso de ironia ou sarcasmo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "HbjXoc1Vb96w",
        "outputId": "f46eec19-fdc6-45a8-8507-5337dc13acae"
      },
      "outputs": [],
      "source": [
        "# Vetorização usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Modelo de classificação\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Previsões\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Relatório de classificação\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvzptnZceWWZ"
      },
      "source": [
        "#### **11) Atividade Opcioanal**\n",
        "\n",
        "\n",
        "Para aprimorar o desempenho do modelo de classificação de sentimentos, explore diferentes combinações de técnicas de pré-processamento de texto, métodos de vetorização e algoritmos de classificação.\n",
        "\n",
        "Considere as seguintes abordagens:\n",
        "\n",
        "1. **Pré-processamento:**\n",
        "   - Aplicação de **Lematização** em vez de Stemming.\n",
        "   - Remoção de **stopwords** específicas do domínio.\n",
        ".\n",
        "\n",
        "2. **Vetorização:**\n",
        "   - Utilização de **TF-IDF** com diferentes parâmetros.\n",
        "  \n",
        "\n",
        "3. **Algoritmos de Classificação:**\n",
        "   - Aplicação de **Máquinas de Vetores de Suporte (SVM)**.\n",
        "   - Teste com **Árvores de Decisão**.\n",
        "   - Avaliação de **Redes Neurais Artificiais**.\n",
        "\n",
        "Para cada combinação, avalie o desempenho utilizando métricas como acurácia, precisão, recall e F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PIACLQTg4GJ"
      },
      "outputs": [],
      "source": [
        "#Resposta"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
